{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Do the prediction tests for the Kaggle competition. We do the following:\n",
    "1. Load and decode the final model from its JSON format. The model was trained in another notebook.\n",
    "2. Test the training error to double check that the model loaded correctly.\n",
    "3. Find the test data predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_src import (my_model,\n",
    "                    my_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode the JSON model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_model.json', 'r') as file:\n",
    "    json_model = file.read()\n",
    "    final_model = json.loads(json_model, object_hook = my_json.as_full_model(LinearDiscriminantAnalysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Training Score of Decoded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 2 * 10**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk  0, Chunk  1, Chunk  2, Chunk  3, Chunk  4, Chunk  5, Chunk  6, Chunk  7, Chunk  8, Chunk  9, "
     ]
    }
   ],
   "source": [
    "# Apply the dimension reduction to the training data.\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "reader = pd.read_csv('data/train.csv', index_col = 'ID_code', chunksize = chunk_size)\n",
    "for i, df in enumerate(reader):\n",
    "    print('Chunk ', i, end = ', ')\n",
    "    X_new = df.drop('target', axis = 1)\n",
    "    y_new = df['target']\n",
    "    X_new = final_model['preprocess'].transform(X_new)\n",
    "    X_train.append(X_new)\n",
    "    y_train.append(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form pandas.DataFrames.\n",
    "\n",
    "X_train = pd.concat(X_train, axis = 0)\n",
    "y_train = pd.concat(y_train, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953335023516895"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the training score.\n",
    "\n",
    "y_predict = final_model['predictor'].predict_proba(X_train)[:, 1]\n",
    "y_predict = pd.Series(y_predict, index = y_train.index)\n",
    "roc_auc_score(y_train, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training score looks good, so the model loaded okay. NOTE, the training score is overly optimistic. The test score should be less as the model slightly overfits the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Test Predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 0, Chunk 1, Chunk 2, Chunk 3, Chunk 4, Chunk 5, Chunk 6, Chunk 7, Chunk 8, Chunk 9, "
     ]
    }
   ],
   "source": [
    "# Reduce the dimensions of the test data.\n",
    "\n",
    "X_test = []\n",
    "reader = pd.read_csv('data/test.csv', index_col = 'ID_code', chunksize = chunk_size)\n",
    "for i, df in enumerate(reader):\n",
    "    print('Chunk', i, end = ', ')\n",
    "    X_new = final_model['preprocess'].transform(df)\n",
    "    X_test.append(X_new)\n",
    "X_test = pd.concat(X_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID_code</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>test_0</th>\n",
       "      <td>0.377315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_1</th>\n",
       "      <td>0.098759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_2</th>\n",
       "      <td>0.195158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_3</th>\n",
       "      <td>0.082016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_4</th>\n",
       "      <td>0.019838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           target\n",
       "ID_code          \n",
       "test_0   0.377315\n",
       "test_1   0.098759\n",
       "test_2   0.195158\n",
       "test_3   0.082016\n",
       "test_4   0.019838"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions.\n",
    "\n",
    "y_test = final_model['predictor'].predict_proba(X_test)[:, 1]\n",
    "y_test = pd.DataFrame(y_test, index = X_test.index, columns = ['target'])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a comma separated file.\n",
    "\n",
    "y_test.to_csv('predictions/final_model.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions are now ready to be submitted to Kaggle for final scoring."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
